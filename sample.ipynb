{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BartTokenizer\n",
    "import torch\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Question</th>\n",
       "      <th>Equation</th>\n",
       "      <th>Input Numbers</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>marian also baked oatmeal cookies for her clas...</td>\n",
       "      <td>how many trays will she need to prepare number...</td>\n",
       "      <td>/ number1 number0</td>\n",
       "      <td>12 276</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>in haley 's class number0 are boys who love to...</td>\n",
       "      <td>how many will each of the boys receive ?</td>\n",
       "      <td>/ number1 number0</td>\n",
       "      <td>5 35</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>jane can arrange number0 vases of flowers in a...</td>\n",
       "      <td>how many days are needed for her to finish all...</td>\n",
       "      <td>/ number1 number0</td>\n",
       "      <td>16 248</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>because of the decision sofia asked the studen...</td>\n",
       "      <td>how many students participated in the suggesti...</td>\n",
       "      <td>+ number0 number1</td>\n",
       "      <td>279 234</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>a fast food restaurant had number0 hotdogs . a...</td>\n",
       "      <td>what 's the difference between the number of h...</td>\n",
       "      <td>- number0 number1</td>\n",
       "      <td>91 20</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description  \\\n",
       "283  marian also baked oatmeal cookies for her clas...   \n",
       "270  in haley 's class number0 are boys who love to...   \n",
       "428  jane can arrange number0 vases of flowers in a...   \n",
       "139  because of the decision sofia asked the studen...   \n",
       "583  a fast food restaurant had number0 hotdogs . a...   \n",
       "\n",
       "                                              Question           Equation  \\\n",
       "283  how many trays will she need to prepare number...  / number1 number0   \n",
       "270           how many will each of the boys receive ?  / number1 number0   \n",
       "428  how many days are needed for her to finish all...  / number1 number0   \n",
       "139  how many students participated in the suggesti...  + number0 number1   \n",
       "583  what 's the difference between the number of h...  - number0 number1   \n",
       "\n",
       "    Input Numbers  Output  \n",
       "283        12 276    23.0  \n",
       "270          5 35     7.0  \n",
       "428        16 248    15.5  \n",
       "139       279 234   513.0  \n",
       "583         91 20    71.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"ArithOpsTrain.xlsx\", header=1)  # header=1 indicates that the second row should be used as the column names\n",
    "\n",
    "# Drop the first column\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Question</th>\n",
       "      <th>Equation</th>\n",
       "      <th>Input Numbers</th>\n",
       "      <th>Output</th>\n",
       "      <th>numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>marian also baked oatmeal cookies for her clas...</td>\n",
       "      <td>how many trays will she need to prepare number...</td>\n",
       "      <td>/ number1 number0</td>\n",
       "      <td>12 276</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>in haley 's class number0 are boys who love to...</td>\n",
       "      <td>how many will each of the boys receive ?</td>\n",
       "      <td>/ number1 number0</td>\n",
       "      <td>5 35</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>jane can arrange number0 vases of flowers in a...</td>\n",
       "      <td>how many days are needed for her to finish all...</td>\n",
       "      <td>/ number1 number0</td>\n",
       "      <td>16 248</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>because of the decision sofia asked the studen...</td>\n",
       "      <td>how many students participated in the suggesti...</td>\n",
       "      <td>+ number0 number1</td>\n",
       "      <td>279 234</td>\n",
       "      <td>513.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>a fast food restaurant had number0 hotdogs . a...</td>\n",
       "      <td>what 's the difference between the number of h...</td>\n",
       "      <td>- number0 number1</td>\n",
       "      <td>91 20</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description  \\\n",
       "283  marian also baked oatmeal cookies for her clas...   \n",
       "270  in haley 's class number0 are boys who love to...   \n",
       "428  jane can arrange number0 vases of flowers in a...   \n",
       "139  because of the decision sofia asked the studen...   \n",
       "583  a fast food restaurant had number0 hotdogs . a...   \n",
       "\n",
       "                                              Question           Equation  \\\n",
       "283  how many trays will she need to prepare number...  / number1 number0   \n",
       "270           how many will each of the boys receive ?  / number1 number0   \n",
       "428  how many days are needed for her to finish all...  / number1 number0   \n",
       "139  how many students participated in the suggesti...  + number0 number1   \n",
       "583  what 's the difference between the number of h...  - number0 number1   \n",
       "\n",
       "    Input Numbers  Output  numbers  \n",
       "283        12 276    23.0        2  \n",
       "270          5 35     7.0        2  \n",
       "428        16 248    15.5        2  \n",
       "139       279 234   513.0        2  \n",
       "583         91 20    71.0        2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(equation):\n",
    "    return equation.count('+') + equation.count('-') + equation.count('/') + equation.count('*') + 1\n",
    "df['numbers'] = df['Equation'].apply(fun)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    754\n",
       "3    225\n",
       "Name: numbers, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['numbers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the DataFrame into a training set (70%) and a testing set (30%)\n",
    "# train_df = df.sample(frac=0.7, random_state=1)  # You can change the random_state for reproducibility\n",
    "# val_df = df.drop(train_df.index)\n",
    "\n",
    "# # Save the training set to a CSV file\n",
    "# train_df.to_csv('training_data.csv', index=False)\n",
    "\n",
    "# # Save the testing set to a CSV file\n",
    "# val_df.to_csv('val_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Question</th>\n",
       "      <th>Equation</th>\n",
       "      <th>Input Numbers</th>\n",
       "      <th>Output</th>\n",
       "      <th>numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen shiela 's brother likes to play with blo...</td>\n",
       "      <td>how many colors did shiela use ?</td>\n",
       "      <td>/ number0 number1</td>\n",
       "      <td>49 7</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isabel received number0 dollars for her birthd...</td>\n",
       "      <td>how many of the toys could she buy ?</td>\n",
       "      <td>/ number0 number1</td>\n",
       "      <td>14 2</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nick saved $ number0 . if nick saved $ number1...</td>\n",
       "      <td>how much did lee save ?</td>\n",
       "      <td>- number0 number1</td>\n",
       "      <td>68.50 25.43</td>\n",
       "      <td>43.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if lewis earns $ number0 every week during the...</td>\n",
       "      <td>how much money does he earn during harvest sea...</td>\n",
       "      <td>* number0 number1</td>\n",
       "      <td>1367.00 5</td>\n",
       "      <td>6835.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amy uploaded number0 pics to facebook . if she...</td>\n",
       "      <td>how many photos were in each album ?</td>\n",
       "      <td>/ number0 number1</td>\n",
       "      <td>180 9</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0  allen shiela 's brother likes to play with blo...   \n",
       "1  isabel received number0 dollars for her birthd...   \n",
       "2  nick saved $ number0 . if nick saved $ number1...   \n",
       "3  if lewis earns $ number0 every week during the...   \n",
       "4  amy uploaded number0 pics to facebook . if she...   \n",
       "\n",
       "                                            Question           Equation  \\\n",
       "0                   how many colors did shiela use ?  / number0 number1   \n",
       "1               how many of the toys could she buy ?  / number0 number1   \n",
       "2                            how much did lee save ?  - number0 number1   \n",
       "3  how much money does he earn during harvest sea...  * number0 number1   \n",
       "4               how many photos were in each album ?  / number0 number1   \n",
       "\n",
       "  Input Numbers   Output  numbers  \n",
       "0          49 7     7.00        2  \n",
       "1          14 2     7.00        2  \n",
       "2   68.50 25.43    43.07        2  \n",
       "3     1367.00 5  6835.00        2  \n",
       "4         180 9    20.00        2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"training_data.csv\")\n",
    "val_df = pd.read_csv('val_data.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptions = list(train_df['Description'].values)\n",
    "train_questions = list(train_df['Question'].values)\n",
    "train_equations = list(train_df['Equation'].values)\n",
    "\n",
    "val_descriptions = list(val_df['Description'].values)\n",
    "val_questions = list(val_df['Question'].values)\n",
    "val_equations = list(val_df['Equation'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Max description+question token length\n",
    "# source_max_len = 0\n",
    "# for i in range(len(descriptions)):\n",
    "#     text = descriptions[i]+\" \"+questions[i]\n",
    "#     tokens = tokenizer(text)['input_ids']\n",
    "#     source_max_len = max(source_max_len,len(list(tokens)))\n",
    "# source_max_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Max equation token length\n",
    "# target_max_len = 0\n",
    "# for i in range(len(descriptions)):\n",
    "#     text = equations[i]\n",
    "#     tokens = tokenizer(text)['input_ids']\n",
    "#     target_max_len = max(target_max_len,len(list(tokens)))\n",
    "# target_max_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathEquationDataset(Dataset):\n",
    "    def __init__(self, descriptions, questions, equations, tokenizer, src_max_length=100,tgt_max_len = 15):\n",
    "        self.descriptions = descriptions\n",
    "        self.questions = questions\n",
    "        self.equations = equations\n",
    "        self.tokenizer = tokenizer\n",
    "        self.src_max_length = src_max_length\n",
    "        self.tgt_max_length = tgt_max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.descriptions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.descriptions[idx] + \" \" + self.questions[idx]\n",
    "        tgt_text = self.equations[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(src_text, return_tensors='pt', max_length=self.src_max_length, padding='max_length', truncation=True)\n",
    "        target = self.tokenizer(tgt_text, return_tensors='pt', max_length=self.tgt_max_length, padding='max_length', truncation=True)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': target['input_ids'].flatten()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_size ==  685\n",
      "Val_size ==  294\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "source_max_len = 100\n",
    "target_max_len = 10\n",
    "\n",
    "# Initialize the Dataset\n",
    "train_dataset = MathEquationDataset(train_descriptions, train_questions, train_equations, tokenizer,src_max_length=source_max_len,tgt_max_len=target_max_len)\n",
    "val_dataset = MathEquationDataset(val_descriptions, val_questions, val_equations, tokenizer,src_max_length=source_max_len,tgt_max_len=target_max_len)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Train_size == \",len(train_dataset))\n",
    "print(\"Val_size == \",len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 20235,   816,  ...,     1,     1,     1],\n",
       "         [    0, 27816,   927,  ...,     1,     1,     1],\n",
       "         [    0, 15796, 28459,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    0,  6709,  7876,  ...,     1,     1,     1],\n",
       "         [    0,   627,  2793,  ...,     1,     1,     1],\n",
       "         [    0,  7456,    21,  ...,     1,     1,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[   0,   12,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 2744, 2055,  346,  134,  346,  176,  346,  246,    2],\n",
       "         [   0, 3226,  346,  134,  346,  176,    2,    1,    1,    1],\n",
       "         [   0, 2744, 2055,  346,  288,  346,  134,  346,  176,    2],\n",
       "         [   0,   12,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 3226,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0,   73,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0,   73,  346,  134,  346,  288,    2,    1,    1,    1],\n",
       "         [   0, 3226,  111,  346,  134,  346,  176,  346,  288,    2],\n",
       "         [   0, 3226,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0,   12,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0,   12,  346,  288, 1009,  346,  176,  346,  134,    2],\n",
       "         [   0, 2744,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0,   12,  111,  346,  288,  346,  134,  346,  176,    2],\n",
       "         [   0, 2744,  346,  134,  346,  176,    2,    1,    1,    1],\n",
       "         [   0, 3226,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  288,  346,  246,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  134,  346,  288,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0,   73,  346,  134,  346,  288,    2,    1,    1,    1],\n",
       "         [   0,   12,  346,  134,  346,  246,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0,   12,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 3226,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0,   12,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0,   12,  346,  288,  346,  134,    2,    1,    1,    1],\n",
       "         [   0, 2744,  346,  288,  346,  134,    2,    1,    1,    1]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "batch = next(train_iter)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>robyn and lucy are members of their village s girl scout troop. during weekends and some weekdays they go around selling cookies in the neighborhood. they have a week before the month ends and they are doing their best to get a badge from selling cookies. working overtime robyn sold number0 packs of cookies while lucy sold number1 how\\tmany packs of cookies were they able to sell that day?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer('robyn and lucy are members of their village s girl scout troop . during weekends and some weekdays they go around selling cookies in the neighborhood . they have a week before the month ends and they are doing their best to get a badge from selling cookies . working overtime robyn sold number0 packs of cookies while lucy sold number1 how\tmany packs of cookies were they able to sell that day ?',max_length=100, padding='max_length', truncation=True)['input_ids']\n",
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>the following week they decided to go to lake huron and lake michigan. during their stay there they caught a total of number0 pikes number1 sturgeons and number2 herrings. how many fishes did they catch from the number3 lakes?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>+ + number0 number1 number2</s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['labels'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, AdamW\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n",
    "model.to('cuda:0')  # or 'cpu' if you are not using a GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device),labels = batch['labels'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 50265])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.9398, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,val_loader,val_dataset):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total_true = []\n",
    "    total_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to('cuda')\n",
    "            attention_mask = batch['attention_mask'].to('cuda')\n",
    "            labels = batch['labels'].to('cuda')\n",
    "\n",
    "\n",
    "            pred_tokens = model.generate(input_ids)\n",
    "            pred_output = [tokenizer.decode(output_id, skip_special_tokens=True) for output_id in pred_tokens]\n",
    "            true_output = [tokenizer.decode(output_id, skip_special_tokens=True) for output_id in labels]\n",
    "\n",
    "            total_true.extend(true_output)\n",
    "            total_pred.extend(pred_output)\n",
    "\n",
    "            # print(\"True == \",true_output)\n",
    "            # print(\"Predicted == \",pred_output)\n",
    "            # print(\"\\n\\n\")\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss = outputs.loss\n",
    "            total_val_loss += val_loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        matching_strings = [a for a, b in zip(total_true, total_pred) if a == b]\n",
    "\n",
    "        # Get the count of matching strings\n",
    "        acc = len(matching_strings)/len(val_dataset)\n",
    "        # print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "        \n",
    "    return avg_val_loss,acc,total_true,total_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manikanta/miniconda3/envs/score/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "train_loss_stat = []\n",
    "val_loss_stat = []\n",
    "best_val_loss = 0.5\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_accuracy = 0.0\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 0, Training Loss: 0.0081, Validation Loss : 0.3209, Val_Accuracy : 0.5986\n",
      "Iter : 10, Training Loss: 0.0838, Validation Loss : 0.3140, Val_Accuracy : 0.5578\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 20, Training Loss: 0.1665, Validation Loss : 0.2997, Val_Accuracy : 0.6054\n",
      "Train_Accuracy : 0.6876\n",
      "Epoch 2/10\n",
      "Iter : 0, Training Loss: 0.0067, Validation Loss : 0.3127, Val_Accuracy : 0.5578\n",
      "Iter : 10, Training Loss: 0.0733, Validation Loss : 0.3333, Val_Accuracy : 0.5442\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 20, Training Loss: 0.1564, Validation Loss : 0.3456, Val_Accuracy : 0.6088\n",
      "Train_Accuracy : 0.7255\n",
      "Epoch 3/10\n",
      "Iter : 0, Training Loss: 0.0060, Validation Loss : 0.4428, Val_Accuracy : 0.5816\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 10, Training Loss: 0.0740, Validation Loss : 0.2871, Val_Accuracy : 0.6429\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 20, Training Loss: 0.1576, Validation Loss : 0.2882, Val_Accuracy : 0.6531\n",
      "Train_Accuracy : 0.8146\n",
      "Epoch 4/10\n",
      "Iter : 0, Training Loss: 0.0049, Validation Loss : 0.2993, Val_Accuracy : 0.6361\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 10, Training Loss: 0.0645, Validation Loss : 0.3441, Val_Accuracy : 0.6599\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 20, Training Loss: 0.1347, Validation Loss : 0.2893, Val_Accuracy : 0.6871\n",
      "Train_Accuracy : 0.8292\n",
      "Epoch 5/10\n",
      "Iter : 0, Training Loss: 0.0039, Validation Loss : 0.2909, Val_Accuracy : 0.6633\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 10, Training Loss: 0.0658, Validation Loss : 0.2817, Val_Accuracy : 0.7075\n",
      "Iter : 20, Training Loss: 0.1463, Validation Loss : 0.4023, Val_Accuracy : 0.6190\n",
      "Train_Accuracy : 0.7124\n",
      "Epoch 6/10\n",
      "Iter : 0, Training Loss: 0.0248, Validation Loss : 0.4343, Val_Accuracy : 0.5340\n",
      "Iter : 10, Training Loss: 0.1685, Validation Loss : 0.4482, Val_Accuracy : 0.6327\n",
      "Iter : 20, Training Loss: 0.2637, Validation Loss : 0.4085, Val_Accuracy : 0.6224\n",
      "Train_Accuracy : 0.7095\n",
      "Epoch 7/10\n",
      "Iter : 0, Training Loss: 0.0072, Validation Loss : 0.3891, Val_Accuracy : 0.4626\n",
      "Iter : 10, Training Loss: 0.1102, Validation Loss : 0.3871, Val_Accuracy : 0.6156\n",
      "Iter : 20, Training Loss: 0.1951, Validation Loss : 0.2968, Val_Accuracy : 0.6939\n",
      "Train_Accuracy : 0.8146\n",
      "Epoch 8/10\n",
      "Iter : 0, Training Loss: 0.0064, Validation Loss : 0.2841, Val_Accuracy : 0.6939\n",
      "Iter : 10, Training Loss: 0.0598, Validation Loss : 0.4100, Val_Accuracy : 0.6769\n",
      "Iter : 20, Training Loss: 0.1235, Validation Loss : 0.3187, Val_Accuracy : 0.6565\n",
      "Train_Accuracy : 0.8423\n",
      "Epoch 9/10\n",
      "Iter : 0, Training Loss: 0.0043, Validation Loss : 0.3343, Val_Accuracy : 0.7075\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 10, Training Loss: 0.0530, Validation Loss : 0.3110, Val_Accuracy : 0.7211\n",
      "Iter : 20, Training Loss: 0.1027, Validation Loss : 0.3426, Val_Accuracy : 0.6667\n",
      "Train_Accuracy : 0.8350\n",
      "Epoch 10/10\n",
      "Iter : 0, Training Loss: 0.0034, Validation Loss : 0.3372, Val_Accuracy : 0.6599\n",
      "Iter : 10, Training Loss: 0.0440, Validation Loss : 0.3781, Val_Accuracy : 0.6667\n",
      "--------- Accuracy Noted ----------\n",
      "Iter : 20, Training Loss: 0.0892, Validation Loss : 0.3767, Val_Accuracy : 0.7313\n",
      "Train_Accuracy : 0.9270\n",
      "Best_acc : 0.7313, Best_epoch : 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i,batch in enumerate(train_loader):\n",
    "        input_ids = batch['input_ids'].to('cuda')\n",
    "        attention_mask = batch['attention_mask'].to('cuda')\n",
    "        labels = batch['labels'].to('cuda')\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i% 10== 0:\n",
    "            model.eval()\n",
    "            avg_val_loss,val_acc,total_true,total_pred = eval(model,val_loader,val_dataset)\n",
    "            model.train()\n",
    "            \n",
    "            avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "            if val_acc > best_accuracy:\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_accuracy = val_acc\n",
    "                best_epoch = epoch+1\n",
    "                print(\"--------- Accuracy Noted ----------\")\n",
    "            train_loss_stat.append(avg_train_loss)\n",
    "            val_loss_stat.append(avg_val_loss)\n",
    "\n",
    "            print(f\"Iter : {i}, Training Loss: {avg_train_loss:.4f}, Validation Loss : {avg_val_loss:.4f}, Val_Accuracy : {val_acc:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    _,train_acc,_,_ = eval(model,train_loader,train_dataset)\n",
    "    print(f\"Train_Accuracy : {train_acc:.4f}\")    \n",
    "    model.train()       \n",
    "\n",
    "\n",
    "print(f\"Best_acc : {best_accuracy:.4f}, Best_epoch : {best_epoch}\")\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3767, Val_Accuracy: 0.7313\n"
     ]
    }
   ],
   "source": [
    "avg_val_loss,acc,total_true,total_pred = eval(model,val_loader,val_dataset)\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}, Val_Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- number1 number0</td>\n",
       "      <td>+ number1 number0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- + number2 number0 number1</td>\n",
       "      <td>- - number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ number1 number0</td>\n",
       "      <td>* number1 number0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- number0 * number1 number2</td>\n",
       "      <td>- - number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- number0 + number1 number2</td>\n",
       "      <td>- + number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>- number1 number0</td>\n",
       "      <td>- number0 number1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>- number1 number0</td>\n",
       "      <td>+ number1 number0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>- number0 number1</td>\n",
       "      <td>+ number0 number1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>- number1 number0</td>\n",
       "      <td>+ number1 number0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>+ + number0 number1 number2</td>\n",
       "      <td>+ - number0 number1 number2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           True                         Pred\n",
       "0             - number1 number0            + number1 number0\n",
       "1   - + number2 number0 number1  - - number0 number1 number2\n",
       "2             / number1 number0            * number1 number0\n",
       "3   - number0 * number1 number2  - - number0 number1 number2\n",
       "4   - number0 + number1 number2  - + number0 number1 number2\n",
       "..                          ...                          ...\n",
       "85            - number1 number0            - number0 number1\n",
       "86            - number1 number0            + number1 number0\n",
       "87            - number0 number1            + number0 number1\n",
       "88            - number1 number0            + number1 number0\n",
       "89  + + number0 number1 number2  + - number0 number1 number2\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_true = []\n",
    "unmatched_pred = []\n",
    "for true,pred in zip(total_true,total_pred):\n",
    "    if true != pred:\n",
    "        unmatched_true.append(true)\n",
    "        unmatched_pred.append(pred)\n",
    "model_df = pd.DataFrame({'True': unmatched_true, 'Pred': unmatched_pred})\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'checkpoint_{20}_temp_acc_0.77')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ==  ['* number0 number1', '- number0 number1', '- number0 number1', '- number0 * number1 number2', '+ number0 number1', '- number0 number1', '+ number0 number1', '+ number0 number1', '+ number0 number1', '/ + number0 number1 number2', '- number0 number1', '- number0 number1', '+ number0 number1', '* number0 number1', '* number0 number1', '- number0 number1', '* number0 number1', '- number0 number1', '* number0 number1', '- number0 number1', '- number0 number1', '+ number0 number1', '+ number0 number1', '* number1 number2', '+ + number0 number1 number2', '/ number1 number0', '* number0 number1', '+ number1 number2', '+ number0 number1', '+ number0 number1', '- number0 number1', '- number0 number1', '+ + number1 number2 number3', '- number0 number1', '+ number5 number1', '+ * number0 number1 number2', '- + number0 number1 number2', '- - number0 number1 number2', '/ number1 number0', '- number0 number1', '* / number1 number0 number2', '* / number1 number0 number2', '- + number0 number1 number2', '+ number0 number1', '/ number0 number1', '+ number0 number1', '* number0 number1', '/ number0 number1', '/ number0 number1', '* number0 number1', '- number0 number1', '+ number0 number1', '+ + number0 number1 number2', '/ number0 number1', '- number0 number1', '- number0 number1', '+ number0 number1', '- number1 number0', '- number1 number0', '- number0 number1', '/ + number1 number2 number0', '- number1 number0', '/ number1 number0', '- number0 number1']\n",
      "Pred ==  ['* number0 number1', '- number0 number1', '- number0 number1', '- number0 number1', '+ number0 number1', '- number0 number1', '+ number0 number1', '+ number0 number1', '+ number0 number1', '/ number0 number1 number2', '- number0 number1', '- number0 number1', '+ number0 number1', '* number0 number1', '* number0 number1', '- number0 number1', '* number0 number1', '- number0 number1', '* number0 number1', '- number0 number1', '- number0 number1', '+ number0 number1', '+ number0 number1', '* number1 number2', '+ number0 number1 number2', '/ number1 number0', '* number0 number1', '+ number1 number2', '+ number0 number1', '+ number0 number1', '- number0 number1', '- number0 number1', '+ number1 number2 number3', '- number0 number1', '+ number5 number1', '+ number0 number1 number2', '- number0 number1 number2', '- - number0 number1 number2', '/ number1 number0', '- number0 number1', '* number0 number1', '* number0 number1', '- number0 number1 number2', '+ number0 number1', '/ number0 number1', '+ number0 number1', '* number0 number1', '/ number0 number1', '/ number0 number1', '* number0 number1', '- number0 number1', '+ number0 number1', '+ number0 number1 number2', '/ number0 number1', '- number0 number1', '- number0 number1', '+ number0 number1', '- number1 number0', '- number1 number0', '- number0 number1', '/ number1 number2 number0', '- number1 number0', '/ number1 number0', '- number0 number1']\n"
     ]
    }
   ],
   "source": [
    "val_iter = iter(val_loader)\n",
    "batch = next(val_iter)\n",
    "pred_tokens = model.generate(batch['labels'].to(device))\n",
    "pred_output = [tokenizer.decode(output_id, skip_special_tokens=True) for output_id in pred_tokens]\n",
    "true_output = [tokenizer.decode(output_id, skip_special_tokens=True) for output_id in batch['labels']]\n",
    "print(\"True == \",true_output)\n",
    "print(\"Pred == \",pred_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, AdamW\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n",
    "model.load_state_dict(torch.load('checkpoint_20_acc_0.77'))\n",
    "model.eval()\n",
    "model.to('cuda:0')  # or 'cpu' if you are not using a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manikanta/miniconda3/envs/score/lib/python3.7/site-packages/transformers/generation/utils.py:1357: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1961, Train_Accuracy: 0.9416\n"
     ]
    }
   ],
   "source": [
    "avg_val_loss,acc,total_true,total_pred = eval(model,train_loader,train_dataset)\n",
    "print(f\"Train Loss: {avg_val_loss:.4f}, Train_Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2062, Val_Accuracy: 0.9252\n"
     ]
    }
   ],
   "source": [
    "avg_val_loss,acc,total_true,total_pred = eval(model,val_loader,val_dataset)\n",
    "print(f\"Val Loss: {avg_val_loss:.4f}, Val_Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- number0 number2</td>\n",
       "      <td>- number0 * number2 number1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- number1 number0</td>\n",
       "      <td>- number0 number1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* + number0 number1 number2</td>\n",
       "      <td>/ + number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+ + number0 number2 number1</td>\n",
       "      <td>+ + number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- number0 number1</td>\n",
       "      <td>- - number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>+ number1 number0</td>\n",
       "      <td>+ number0 number1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>+ + number0 number1 number2</td>\n",
       "      <td>- - number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>+ + number0 number2 number1</td>\n",
       "      <td>+ + number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/ number1 number2</td>\n",
       "      <td>/ number1 number2 number0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>- - number0 number1 number2</td>\n",
       "      <td>+ - number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>- number2 number1</td>\n",
       "      <td>- number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>* number0 number1</td>\n",
       "      <td>/ number0 number1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>- number0 number1</td>\n",
       "      <td>+ number0 number1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>- + number0 number1 number2</td>\n",
       "      <td>+ + number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>* - number0 number1 number2</td>\n",
       "      <td>/ number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>- - number0 number1 number2</td>\n",
       "      <td>- number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>* + number1 number2 number0</td>\n",
       "      <td>* * number0 number1 number2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>- - number2 number0 number1</td>\n",
       "      <td>- number2 number0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>+ number0 number1</td>\n",
       "      <td>- number0 number1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>- number1 number0</td>\n",
       "      <td>- number0 number1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/ number1 number2</td>\n",
       "      <td>/ number1 number2 number0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>- number0 number1</td>\n",
       "      <td>+ number0 number1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           True                         Pred\n",
       "0             - number0 number2  - number0 * number2 number1\n",
       "1             - number1 number0            - number0 number1\n",
       "2   * + number0 number1 number2  / + number0 number1 number2\n",
       "3   + + number0 number2 number1  + + number0 number1 number2\n",
       "4             - number0 number1  - - number0 number1 number2\n",
       "5             + number1 number0            + number0 number1\n",
       "6   + + number0 number1 number2  - - number0 number1 number2\n",
       "7   + + number0 number2 number1  + + number0 number1 number2\n",
       "8             / number1 number2    / number1 number2 number0\n",
       "9   - - number0 number1 number2  + - number0 number1 number2\n",
       "10            - number2 number1            - number1 number2\n",
       "11            * number0 number1            / number0 number1\n",
       "12            - number0 number1            + number0 number1\n",
       "13  - + number0 number1 number2  + + number0 number1 number2\n",
       "14  * - number0 number1 number2    / number0 number1 number2\n",
       "15  - - number0 number1 number2            - number1 number2\n",
       "16  * + number1 number2 number0  * * number0 number1 number2\n",
       "17  - - number2 number0 number1            - number2 number0\n",
       "18            + number0 number1            - number0 number1\n",
       "19            - number1 number0            - number0 number1\n",
       "20            / number1 number2    / number1 number2 number0\n",
       "21            - number0 number1            + number0 number1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_true = []\n",
    "unmatched_pred = []\n",
    "for true,pred in zip(total_true,total_pred):\n",
    "    if true != pred:\n",
    "        unmatched_true.append(true)\n",
    "        unmatched_pred.append(pred)\n",
    "model_df = pd.DataFrame({'True': unmatched_true, 'Pred': unmatched_pred})\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_equation(model,sentence):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", max_length=100, truncation=True)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(**inputs)\n",
    "    decoded_output = [tokenizer.decode(output_id, skip_special_tokens=True) for output_id in outputs]\n",
    "    return outputs,decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['* number0 number1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manikanta/miniconda3/envs/score/lib/python3.7/site-packages/transformers/generation/utils.py:1357: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "description = \"the kids from oakwood elementary school are visiting a bird zoo for their field trip . to get to the bird zoo from the school the kids have to ride some buses . if there are number0 buses and each bus has number1 adult supervisors to guide the children\thow many supervisors are there in total ?\"\n",
    "outputs,predicted_equation = generate_equation(model,description)\n",
    "print(predicted_equation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    0, 3226,  346,  288,  346,  134,    2]], device='cuda:0')\n",
      "</s><s>* number0 number1</s>\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3226, 346, 288, 346, 134, 2]\n",
      "<s>* number0 number1</s>\n"
     ]
    }
   ],
   "source": [
    "tgt = \"* number0 number1\"\n",
    "ids = tokenizer(tgt)['input_ids']\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s><s>* number0 number1</s>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 8.0\n"
     ]
    }
   ],
   "source": [
    "def evaluate_prefix(expression, operands):\n",
    "    # Split the expression into tokens\n",
    "    tokens = expression.split()\n",
    "\n",
    "    # Define a stack to store operands\n",
    "    stack = []\n",
    "\n",
    "    # Iterate through the tokens in reverse order (as it's a prefix expression)\n",
    "    for token in reversed(tokens):\n",
    "        try:\n",
    "            if token.startswith('number'):\n",
    "                # If the token starts with 'number', use it to index into the 'operands' list\n",
    "                operand_index = int(token[6:])  # Extract the index from the token\n",
    "                if 0 <= operand_index < len(operands):\n",
    "                    stack.append(float(operands[operand_index]))\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid operand index: \" + str(operand_index))\n",
    "            elif token in '+-*/':\n",
    "                # If the token is an operator, pop two operands from the stack and apply the operator\n",
    "                operand1 = stack.pop()\n",
    "                operand2 = stack.pop()\n",
    "                if token == '+':\n",
    "                    stack.append(operand1 + operand2)\n",
    "                elif token == '-':\n",
    "                    stack.append(operand1 - operand2)\n",
    "                elif token == '*':\n",
    "                    stack.append(operand1 * operand2)\n",
    "                elif token == '/':\n",
    "                    if operand2 == 0:\n",
    "                        raise ValueError(\"Division by zero\")\n",
    "                    stack.append(operand1 / operand2)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid token: \" + token)\n",
    "        except (ValueError, IndexError):\n",
    "            return None  # Handle the error and return None\n",
    "\n",
    "    if len(stack) != 1:\n",
    "        return None  # Return None for any errors\n",
    "\n",
    "    return stack[0]\n",
    "\n",
    "# Example usage:\n",
    "expression = '+ * number0 number1 number2'\n",
    "operands = [1, 3, 5]\n",
    "result = evaluate_prefix(expression, operands)\n",
    "\n",
    "if result is not None:\n",
    "    print(\"Result:\", result)\n",
    "else:\n",
    "    print(\"Error: Invalid expression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Question</th>\n",
       "      <th>Input Numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>number0 red apples and number1 green apples ar...</td>\n",
       "      <td>how many apples are in the basket ?</td>\n",
       "      <td>7 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ellen has number0 more balls than marin . mari...</td>\n",
       "      <td>how many balls does ellen have ?</td>\n",
       "      <td>6 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>janet has number0 oranges and sharon has numbe...</td>\n",
       "      <td>how many oranges do janet and sharon have toge...</td>\n",
       "      <td>9 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allan brought number0 balloons and jake brough...</td>\n",
       "      <td>how many balloons did allan and jake have in t...</td>\n",
       "      <td>2 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adam has number0 more apples than jackie . jac...</td>\n",
       "      <td>how many apples does adam have ?</td>\n",
       "      <td>5 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0  number0 red apples and number1 green apples ar...   \n",
       "1  ellen has number0 more balls than marin . mari...   \n",
       "2  janet has number0 oranges and sharon has numbe...   \n",
       "3  allan brought number0 balloons and jake brough...   \n",
       "4  adam has number0 more apples than jackie . jac...   \n",
       "\n",
       "                                            Question Input Numbers  \n",
       "0                how many apples are in the basket ?           7 2  \n",
       "1                   how many balls does ellen have ?           6 9  \n",
       "2  how many oranges do janet and sharon have toge...           9 7  \n",
       "3  how many balloons did allan and jake have in t...           2 4  \n",
       "4                   how many apples does adam have ?           5 9  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_excel('ArithOpsTestDataWithoutOutput.xlsx')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manikanta/miniconda3/envs/score/lib/python3.7/site-packages/transformers/generation/utils.py:1357: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# true = list(test_df['Output'].values)\n",
    "pred = []\n",
    "ind = 0\n",
    "for index, row in test_df.iterrows():\n",
    "    ind+=1\n",
    "    if ind%50 == 0:\n",
    "        print(ind)\n",
    "    input = row['Description']+\" \"+row['Question']\n",
    "    _,predicted_equation = generate_equation(model,input)\n",
    "    predicted_equation = predicted_equation[0]\n",
    "    pred_output = evaluate_prefix(predicted_equation, row['Input Numbers'].split())\n",
    "    pred.append(pred_output)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bandla Manikanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0  Bandla Manikanta\n",
       "1               9.0\n",
       "2              15.0\n",
       "3               2.0\n",
       "4               6.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pred)\n",
    "df.to_excel('output.xlsx', index=False, header=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Output\n",
       "0     9.0\n",
       "1    15.0\n",
       "2    16.0\n",
       "3     6.0\n",
       "4    14.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('ArithOpsTestDataOnlyOutput.xlsx')\n",
    "true = list(df['Output'].values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7563025210084033"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for a,b in zip(true,pred):\n",
    "    if a==b:\n",
    "        correct+=1\n",
    "correct/len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "score",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
